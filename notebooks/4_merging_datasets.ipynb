{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define file paths\n",
    "btc_price_path = \"../datasets/normalised_bitcoin_price.parquet\"\n",
    "sentiment_path = \"../datasets/daily_sentiment.parquet\"\n",
    "\n",
    "# Load datasets\n",
    "btc_data = pd.read_parquet(btc_price_path)\n",
    "sentiment_data = pd.read_parquet(sentiment_path)\n",
    "\n",
    "# Convert 'date' columns to datetime format (if not already)\n",
    "btc_data['date'] = pd.to_datetime(btc_data['date'])\n",
    "sentiment_data['date'] = pd.to_datetime(sentiment_data['date'])\n",
    "\n",
    "# Display loaded datasets\n",
    "print(\"Bitcoin Price Data:\")\n",
    "print(btc_data.head())\n",
    "print(\"\\nSentiment Data:\")\n",
    "print(sentiment_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure both VADER and BERT sentiment scores are included in sentiment_data\n",
    "if 'bert_sentiment' not in sentiment_data.columns:\n",
    "    raise ValueError(\"BERT sentiment score column is missing in sentiment dataset!\")\n",
    "\n",
    "# Merge on 'date' column (inner join to keep common dates)\n",
    "merged_data = pd.merge(btc_data, sentiment_data, on='date', how='inner')\n",
    "\n",
    "# Display merged dataset\n",
    "print(\"Merged Dataset with VADER & BERT Sentiments:\")\n",
    "print(merged_data[['date', 'Close', 'sentiment_score', 'bert_sentiment']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lag features (Previous day's Close price, VADER sentiment, BERT sentiment)\n",
    "merged_data['prev_close'] = merged_data['Close'].shift(1)\n",
    "merged_data['prev_vader_sentiment'] = merged_data['sentiment_score'].shift(1)\n",
    "merged_data['prev_bert_sentiment'] = merged_data['bert_sentiment'].shift(1)\n",
    "\n",
    "# Display dataset with lag features\n",
    "print(\"Dataset with Lag Features:\")\n",
    "print(merged_data[['date', 'Close', 'prev_close', 'sentiment_score', 'bert_sentiment', 'prev_vader_sentiment', 'prev_bert_sentiment']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lag features (Previous day's Close price, VADER sentiment, BERT sentiment)\n",
    "merged_data['prev_close'] = merged_data['Close'].shift(1)\n",
    "merged_data['prev_vader_sentiment'] = merged_data['sentiment_score'].shift(1)\n",
    "merged_data['prev_bert_sentiment'] = merged_data['bert_sentiment'].shift(1)\n",
    "\n",
    "# Display dataset with lag features\n",
    "print(\"Dataset with Lag Features:\")\n",
    "print(merged_data[['date', 'Close', 'prev_close', 'sentiment_score', 'bert_sentiment', 'prev_vader_sentiment', 'prev_bert_sentiment']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Volatility indicators (Standard Deviation)\n",
    "merged_data['volatility_7d'] = merged_data['Close'].rolling(window=7).std()\n",
    "merged_data['volatility_14d'] = merged_data['Close'].rolling(window=14).std()\n",
    "merged_data['volatility_30d'] = merged_data['Close'].rolling(window=30).std()\n",
    "\n",
    "# Display dataset with volatility indicators\n",
    "print(\"Dataset with Volatility Indicators:\")\n",
    "\n",
    "print(merged_data[['date', 'Close', 'volatility_7d', 'volatility_14d', 'volatility_30d']].head(15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing values: Forward Fill (then Backward Fill if needed)\n",
    "merged_data.fillna(method='ffill', inplace=True)\n",
    "merged_data.fillna(method='bfill', inplace=True)\n",
    "\n",
    "# Display final dataset\n",
    "print(\"Final Dataset After Handling Missing Values:\")\n",
    "print(merged_data.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final processed dataset\n",
    "final_dataset_path = \"../datasets/final_merged_dataset.parquet\"\n",
    "merged_data.to_parquet(final_dataset_path, index=False)\n",
    "\n",
    "print(f\"Processed dataset saved at: {final_dataset_path}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
